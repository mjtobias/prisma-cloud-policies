{
  "policyUpi": "PC-GCP-GKE-204",
  "policyId": "1478c66d-2911-4a19-80fb-ddc36ab2a270",
  "policyType": "config",
  "cloudType": "gcp",
  "severity": "low",
  "name": "GCP Kubernetes Engine Clusters not configured with private cluster",
  "description": "This policy identifies Kubernetes Engine Clusters which are not configured with the Private cluster. Private cluster makes your master inaccessible from the public internet and nodes do not have public IP addresses, so your workloads run in an environment that is isolated from the internet.",
  "rule.criteria": "f698d4a8-6ee8-40b4-9cf1-211901b00ca3",
  "searchModel.query": "config from cloud.resource where cloud.type = 'gcp' AND api.name = 'gcloud-container-describe-clusters' AND json.rule =  'privateCluster does not exist or privateCluster is false'",
  "recommendation": "GCP Kubernetes private cluster option can be enabled at the time of cluster creation. So to fix this alert, Create a new cluster with a private cluster configured on it and migrate all required data from reported cluster to the newly created cluster.\n\n1. Login to GCP Portal\n2. Click on 'CREATE CLUSTER'\n3. Choose the required name/value for other cluster fields\n4. Click on 'Advanced options'\n5. Under the Networking section, Check the 'Enable VPC-native (using alias IP)' option\n6. Choose the required Network, Node subnet parameters\n7. In the Network security section, Check the 'Private cluster' option\n8. Set 'Master IP range' to as per your required IP range\n9. Click on 'Create'\nNOTE: When you create a private cluster, you must specify a /28 CIDR range for the VMs that run the Kubernetes master components. You also need to enable IP aliases.",
  "remediable": false,
  "remediation.cliScriptTemplate": "",
  "remediation.description": "",
  "remediation.impact": "",
  "compliance.standard": [
    "CCPA 2018",
    "CIS v1.0.0 (GCP)",
    "ISO 27001:2013",
    "PIPEDA"
  ]
}